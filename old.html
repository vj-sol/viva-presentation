<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <meta name="author" content="Vijay Solanki">

    <title>Brains in Dialogue</title>

    <link rel="stylesheet" href="css/reveal.css">
    <link rel="stylesheet" href="css/theme/simple.css">

    <!-- Theme used for syntax highlighting of code -->
    <!--     <link rel="stylesheet" href="lib/css/atelier-heath-dark.css"> -->
    <link rel="stylesheet" href="lib/css/zenburn.css">

    <!--Add support for earlier versions of Internet Explorer -->
    <!--[if lt IE 9]>
<script src="lib/js/html5shiv.js"></script>
<![endif]-->

    <!-- Printing and PDF exports -->
    <script>
      var link = document.createElement( 'link' );
      link.rel = 'stylesheet';
      link.type = 'text/css';
      link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
      document.getElementsByTagName( 'head' )[0].appendChild( link );
    </script>

  </head>
  <body>
    <div class="reveal">
      <header style="position: absolute;top: 50px; left: 100px; z-index:500; font-size:30px;"></header>
      <div class="slides">


        <!--    NEW TOP LEVEL SLIDE      -->
        <section>
          <section data-background-image='./resources/image13.jpg' align='left'>
            <div style='position:absolute; top:-50px; left:-250px'>
              <h2>
                Brains in Dialogue
              </h2>
              <h4>
                Investigating accommodation in live conversational speech <br>for both speech and EEG data
              </h4>
              <br>
              <h4>
                Vijay Solanki, MA(Hons)
              </h4>
            </div>

            <!--             <h4>
April 27<sup><small>th</small></sup> 2017
</h4> -->
            <!--             <h6>
Glasgow University Laboratory of Phonetics
</h6> -->
            <aside class='notes'>

            </aside>
          </section>
          <!--           <section>
<h3>
Feedback
</h3>
</section> -->

        </section>




        <!--    NEW TOP LEVEL SLIDE      -->
        <section align='left'>

          <section>
            <h2 align='center'>
              The Aim
              <!--               Why was the problem important and how did it arise? -->
            </h2>
            <aside class='notes'>

            </aside>
          </section>

          <section data-background-image='./resources/image24.jpg'>

          </section>

          <section>
            <h3>
              Main Research Question:
            </h3>
            <p>
              Is <span class='fragment highlight-red data-fragment-index='1''>speech accommodation</span> linked to the <span class='fragment highlight-red data-fragment-index='1''>alignment of mental representations</span> as accounted for through <span class='fragment highlight-red data-fragment-index='1''>observable brain activity</span>?
            </p>
            <aside class='notes'>

            </aside>
          </section>
        </section>

        <!--    NEW TOP LEVEL SLIDE      -->
        <section align='left'>

          <section>
            <h2 align='center'>
              The Background
              <!--           What have others done? -->
            </h2>
            <aside class='notes'>
            </aside>
          </section>

          <section>
            <div style='font-size:60%'>
              <h2>
                What, How, Why and How
              </h2>
              <br>
              <h3 style='color:red'>
                Speech accommodation
              </h3>
              <h4>
                What is accommodation?
              </h4>
              <h4>
                How is accommodation measured?
              </h4>
              <br>
              <h3 style='color:red'>
                Alignment of mental representations
              </h3>
              <h4>
                Why should accommodation be linked to joint brain activity?
              </h4>
              <br>
              <h3 style='color:red'>
                Observable brain activity
              </h3>
              <h4>
                How can accommodation &amp; brain activity be measured in tandem?
              </h4>
            </div>
            <aside class='notes'>

            </aside>
          </section>

          <section>
            <h3>
              What is accommodation?
            </h3>
          </section>

          <section data-state="header1">
            <style>.header1 header:after { content: "What is accommodation?"; }</style>
            <p>
              The tendency of a speaker to adjust their production of speech sounds in relation to the person (or persons) that they are speaking to
            </p>
            <p class='fragment'>
              Why do we observe this phenomenon?
            </p>
            <ul>
              <li class='fragment'>Communication Accommodation Theory
                <p>
                  Perception of the intentions and behaviours of an interlocutor influence the levels and types of accommodation
                </p></li>
            </ul>
            <!--             <p>Non-linguistic factors</p> -->
          </section>

          <section data-state="header1" align='left'>
            <style>.header1 header:after { content: "What is accommodation?"; }</style>
            <!--             <div align='center'> -->
            <!--               <img src='./resources/lit-rev-what-acc-types.png' style='height:650px;border:0;box-shadow:none'> -->
            <div align='left'>
              <table class='stretch'>
                <tr>
                  <td style='border:none; text-align:left; vertical-align:middle; color:#F8766D'>Convergence</td>
                  <td style='border:none'>
                    <svg width='250' height='150'>
                      <polygon points='10,10,10,150'
                               style="fill:lime;stroke:#F8766D;stroke-width:3;fill-rule:evenodd;" />
                      <polygon points='0,140,290,140'
                               style="fill:lime;stroke:#F8766D;stroke-width:3;fill-rule:evenodd;" />
                      <polygon points='20,50,290,100'
                               style="fill:lime;stroke:#F8766D;stroke-width:3;fill-rule:evenodd;" />
                      <polygon points='20,100,290,100'
                               style="fill:lime;stroke:#F8766D;stroke-width:3;fill-rule:evenodd;" />
                    </svg></td>
                  <td style='border:none'>
                    <svg width='250' height='150'>
                      <polygon points='10,10,10,150'
                               style="fill:lime;stroke:#F8766D;stroke-width:3;fill-rule:evenodd;" />
                      <polygon points='0,140,290,140'
                               style="fill:lime;stroke:#F8766D;stroke-width:3;fill-rule:evenodd;" />
                      <polygon points='20,50,290,50'
                               style="fill:lime;stroke:#F8766D;stroke-width:3;fill-rule:evenodd;" />
                      <polygon points='20,100,290,50'
                               style="fill:lime;stroke:#F8766D;stroke-width:3;fill-rule:evenodd;" />
                    </svg></td>
                  <td style='border:none'>
                    <svg width='250' height='150'>
                      <polygon points='10,10,10,150'
                               style="fill:lime;stroke:#F8766D;stroke-width:3;fill-rule:evenodd;" />
                      <polygon points='0,140,290,140'
                               style="fill:lime;stroke:#F8766D;stroke-width:3;fill-rule:evenodd;" />
                      <polygon points='20,50,290,75'
                               style="fill:lime;stroke:#F8766D;stroke-width:3;fill-rule:evenodd;" />
                      <polygon points='20,100,290,75'
                               style="fill:lime;stroke:#F8766D;stroke-width:3;fill-rule:evenodd;" />
                    </svg></td>
                </tr>
                <tr>
                  <td style='border:none; text-align:left; vertical-align:middle; color:#7CAE00'>Divergence</td>
                  <td style='border:none'>
                    <svg width='250' height='150'>
                      <polygon points='10,0,10,150'
                               style="fill:lime;stroke:#7CAE00;stroke-width:3;fill-rule:evenodd;" />
                      <polygon points='0,140,290,140'
                               style="fill:lime;stroke:#7CAE00;stroke-width:3;fill-rule:evenodd;" />
                      <polygon points='20,50,290,0'
                               style="fill:lime;stroke:#7CAE00;stroke-width:3;fill-rule:evenodd;" />
                      <polygon points='20,100,290,100'
                               style="fill:lime;stroke:#7CAE00;stroke-width:3;fill-rule:evenodd;" />
                    </svg></td>
                  <td style='border:none'>
                    <svg width='250' height='150'>
                      <polygon points='10,10,10,200'
                               style="fill:lime;stroke:#7CAE00;stroke-width:3;fill-rule:evenodd;" />
                      <polygon points='0,140,290,140'
                               style="fill:lime;stroke:#7CAE00;stroke-width:3;fill-rule:evenodd;" />
                      <polygon points='20,50,290,50'
                               style="fill:lime;stroke:#7CAE00;stroke-width:3;fill-rule:evenodd;" />
                      <polygon points='20,100,290,130'
                               style="fill:lime;stroke:#7CAE00;stroke-width:3;fill-rule:evenodd;" />
                    </svg></td>
                  <td style='border:none'>
                    <svg width='250' height='150'>
                      <polygon points='10,10,10,150'
                               style="fill:lime;stroke:#7CAE00;stroke-width:3;fill-rule:evenodd;" />
                      <polygon points='0,140,290,140'
                               style="fill:lime;stroke:#7CAE00;stroke-width:3;fill-rule:evenodd;" />
                      <polygon points='20,50,290,0'
                               style="fill:lime;stroke:#7CAE00;stroke-width:3;fill-rule:evenodd;" />
                      <polygon points='20,100,290,130'
                               style="fill:lime;stroke:#7CAE00;stroke-width:3;fill-rule:evenodd;" />
                    </svg></td>
                </tr>
                <tr>
                  <td style='border:none; text-align:left; vertical-align:middle; color:#00BFC4'>Complimentarity</td>
                  <td style='border:none'>
                    <svg width='250' height='150'>
                      <polygon points='10,10,10,150'
                               style="fill:lime;stroke:#00BFC4;stroke-width:3;fill-rule:evenodd;" />
                      <polygon points='0,140,290,140'
                               style="fill:lime;stroke:#00BFC4;stroke-width:3;fill-rule:evenodd;" />
                      <polygon points='20,50,290,80'
                               style="fill:lime;stroke:#00BFC4;stroke-width:3;fill-rule:evenodd;" />
                      <polygon points='20,100,290,130'
                               style="fill:lime;stroke:#00BFC4;stroke-width:3;fill-rule:evenodd;" />
                    </svg></td>
                  <td style='border:none'>
                    <svg width='250' height='150'>
                      <polygon points='10,10,10,150'
                               style="fill:lime;stroke:#00BFC4;stroke-width:3;fill-rule:evenodd;" />
                      <polygon points='0,140,290,140'
                               style="fill:lime;stroke:#00BFC4;stroke-width:3;fill-rule:evenodd;" />
                      <polygon points='20,50,290,0'
                               style="fill:lime;stroke:#00BFC4;stroke-width:3;fill-rule:evenodd;" />
                      <polygon points='20,100,290,50'
                               style="fill:lime;stroke:#00BFC4;stroke-width:3;fill-rule:evenodd;" />
                    </svg></td>
                </tr>
                <tr>
                  <td style='border:none; text-align:left; vertical-align:middle; color:#C77CFF'>Maintenance</td>
                  <td style='border:none'>
                    <svg width='250' height='150'>
                      <polygon points='10,10,10,150'
                               style="fill:lime;stroke:#C77CFF;stroke-width:3;fill-rule:evenodd;" />
                      <polygon points='0,140,290,140'
                               style="fill:lime;stroke:#C77CFF;stroke-width:3;fill-rule:evenodd;" />
                      <polygon points='20,50,290,50'
                               style="fill:lime;stroke:#C77CFF;stroke-width:3;fill-rule:evenodd;" />
                      <polygon points='20,100,290,100'
                               style="fill:lime;stroke:#C77CFF;stroke-width:3;fill-rule:evenodd;" />
                    </svg></td>
                </tr>
              </table>
            </div>
            <!--   <polygon points="10,10 40,198 190,78 10,78 160,198" -->
            <!--             </div> -->
            <p class='fragment'>However, findings are complex and and do not seem to follow a simple pattern</p>
          </section>

          <section>
            <h3>
              How is accommodation measured?
            </h3>
          </section>

          <section data-state="header2" align='center'>
            <style>.header2 header:after { content: "How is accommodation measured?"; }</style>
            <table>
<tr><th style='border:none'></th><th style='border:none'></th><th colspan='2' align='center' style='border:none'>Stimuli</th></tr>
<tr><td style='border:none'></td><td style='border:none'></td><td style='border:none'>Interactional</td><td style='border:none'>Non-Interactional</td></tr>
<tr><th rowspan='2' align='center' style='border:none'>Measure</th><td style='border:none'>Perceptual</td><td style='border:none'></td><td style='border:none'></td></tr>
<tr><td>Acoustic-Phonetic</td><td></td><td></td></tr>
            </table>
<!--             <div style='font-size:80%'>
              <ul>
                <li>
                  Perceptual Interaction Approaches
                  <p>
                    Measures accommodation using the human perceptual system from interactional stimuli
                  </p>
                </li>
                <li class='fragment'>
                  Perceptual Non-Interaction Approaches
                  <p>
                    Measures accommodation using the human perceptual system from non-interactional stimuli
                  </p>
                </li>
                <li class='fragment'>
                  Acoustic-phonetic Non-Interaction Approaches
                  <p>
                    Measures accommodation using acoustic-phonetic features from non-interactional stimuli
                  </p>
                </li>
                <li class='fragment'>
                  Acoustic-phonetic Interaction Approaches
                  <p>
                    Measures accommodation using acoustic-phonetic features from interactional stimuli
                  </p>
                </li>
              </ul>
            </div> -->
          </section>

<!--           <section data-state="header2" align='center'>
            <style>.header2 header:after { content: "How is accommodation measured?"; }</style>
            <img src='./resources/quadrant.png' style='height:750px;border:0;box-shadow:none'>
          </section> -->

          <section data-state="header2" align='left'>
            <style>.header2 header:after { content: "How is accommodation measured?"; }</style>
            <p>
              All approaches offer insight into how accommodation operates and what its underlying mechanisms are
            </p>
            <p class='fragment' data-fragment-index='1'>
              However, most rely on carry over effects and cannot evaluate accommodation 'in situ'
            </p>
            <table>
              <tr>
                <td style='border:none' class='fragment'  data-fragment-index='1'>
                    <svg width='400' height='400'>
                      <polygon points='10,10,10,400'
                               style="fill:lime;stroke:black;stroke-width:3;fill-rule:evenodd;" />
                      <polygon points='0,390,400,390'
                               style="fill:lime;stroke:black;stroke-width:3;fill-rule:evenodd;" />
                      <polygon points='20,180,390,100'
                               style="fill:lime;stroke:red;stroke-width:3;fill-rule:evenodd;" />
                      <polygon points='20,220,390,220'
                               style="fill:lime;stroke:blue;stroke-width:3;fill-rule:evenodd;" />
                    </svg></td>
<!--                 <td class='fragment'><img src='./resources/acc-dummy-blank.png' style='border:none; box-shadow:none'></td> -->
                <td style='border:none'  class='fragment' data-fragment-index='2'>
                    <svg width='400' height='400'>
                      <polygon points='10,10,10,400'
                               style="fill:lime;stroke:black;stroke-width:3;fill-rule:evenodd;" />
                      <polygon points='0,390,400,390'
                               style="fill:lime;stroke:black;stroke-width:3;fill-rule:evenodd;" />
                      <polygon points='20,180,390,100'
                               style="fill:lime;stroke:red;stroke-width:3;fill-rule:evenodd;" />
                      <polygon points='20,220,390,220'
                               style="fill:lime;stroke:blue;stroke-width:3;fill-rule:evenodd;" />
                      <polyline points='20,180 40,180 60,180 80,190 100,180 120,200 140,180 160,160 180,170 200,160 220,190 240,160 260,180 280,200 300,160 320,140 340,180 360,110 380,110 390,100'
                               style="stroke:red;stroke-width:3;fill:none;stroke-dasharray:1, 3" />
                      <polyline points='20,220 40,240 60,200 80,200 100,200 120,240 140,220 160,200 180,220 200,200 220,190 240,200 260,220 280,180 300,160 320,180 340,220 360,230 380,200 390,220'
                               style="stroke:blue;stroke-width:3;fill:none;stroke-dasharray:1, 3" />
                    </svg></td>
<!--                 <td class='fragment'><img src='./resources/acc-dummy-trail.png' style='border:none; box-shadow:none'></td> -->
              </tr>
            </table>
          </section>

          <section>
            <h3>
              Why should accommodation be linked to joint brain activity?
            </h3>
          </section>

          <section data-state="header3">
            <style>.header3 header:after { content: "Why should accommodation be linked to joint brain activity?"; }</style>
            <h3>
              The cognitive mechanisms underlying accommodation (Pardo, 2016)
            </h3>
            <ul>
              <li>The motor theory of speech</li>
              <li>Direct realism</li>
              <li>Phonetic detail in episodic memory</li>
              <li>Mechanistic language use in dialogue</li>
            </ul>
            <p>
              All assume a non-trivial link between production and perception
            </p>
            <!--             <ul>
<li>Cognitive mechanisms underlying accommodation</li>
<li>Neural entrainment</li>
<li>Accommodation and brain activity</li>
</ul> -->
          </section>

          <section data-state="header3" align='center'>
            <style>.header3 header:after { content: "Why should accommodation be linked to joint brain activity?"; }</style>
            <h3 align='left'>
              Neural entrainment
            </h3>
            <img src='./resources/phase-processing.jpg' style='border:none; box-shadow:none'>
          </section>

          <section data-state="header3" align='center'>
            <style>.header3 header:after { content: "Why should accommodation be linked to joint brain activity?"; }</style>
            <h3 align='left'>
              Neural entrainment to speech
            </h3>
            <img src='./resources/giraud-oscillations.png' style='border:none; box-shadow:none'>
          </section>

          <section data-state="header3">
            <style>.header3 header:after { content: "Why should accommodation be linked to joint brain activity?"; }</style>
            <p>
              Neural entrainment to the speech of another speaker could produce a degree of inter-speaker entrainment
            </p>
            <p class='fragment'>
              This would be especially true in situations that require high levels of coordination
            </p>
          </section>

          <section>
            <h3>
              How can accommodation &amp; brain activity be measured in tandem?
            </h3>
          </section>

          <!--           <section data-state="header4">
<style>.header4 header:after { content: "How can accommodation & brain activity be measured in tandem?"; }</style>
<ul>
<li>Hidden Markov Models (HMMs) and speech data</li>
<li>Extending to EEG data</li>
</ul>
</section> -->

          <section data-state="header4">
            <style>.header4 header:after { content: "How can accommodation & brain activity be measured in tandem?"; }</style>
            <h3 align='left'>
              Hidden Markov Models (HMMS) and speech data
            </h3>
            <p>
              Markov chains
            </p>
            <div align='center'>
              <img src='./resources/markov-chain.png' style='border:none; box-shadow:none'width=900px>
            </div>
          </section>

          <section data-state='header4'>
            <style>.header4 header:after { content: "How can accommodation & brain activity be measured in tandem?"; }</style>
            <div align='center'>
              <img src='./resources/HMM-speech.png' style='border:none; box-shadow:none'width=900px>
            </div>
            <p class='fragment'>
              In this way, HMMs are able to characterise the general form of a continuous signal.
            </p>
          </section>

          <section  data-state="header4">
            <style>.header4 header:after { content: "How can accommodation & brain activity be measured in tandem?"; }</style>
            <h3>
              Extending to EEG data
            </h3>

            <p>
              There are 2 key considerations for the inclusion of EEG in this thesis:
            </p>
            <ol>
              <li>How to assess a continuous EEG signal for effects related to speech accommodation</li>
              <li>How to eliminate muscular artefacts associated with speech from the EEG signal</li>
              <!--               <li>How to perform an EEG hyperscanning experiment whilst recording speech</li> -->
            </ol>
            <aside class='notes'>
              <p>
                HMMs are domain independent, meaning that they can be applied to any signal source that varies with respect to another dimension.

                Recent advances
              </p>
            </aside>
          </section>

          <section  data-state="header4">
            <style>.header4 header:after { content: "How can accommodation & brain activity be measured in tandem?"; }</style>
            <h3>
              Consideration 1:
            </h3>
            <p>
              Unlike the speech signal, the EEG signal is much weaker and is more prone to noise
            </p>
            <p class='fragment'>
              For this reason, traditional approaches average the signal over a number of trials to eliminate random noise
            </p>
            <p class='fragment'>
              This is not possible for accommodation detection in a continuous setting, instead we apply HMMs
            </p>
            <p class='fragment'>
              By characterising the general form of each participant's neural activity, we can look for deviations towards or away from that of their partners
            </p>
          </section>

          <section  data-state="header4">
            <style>.header4 header:after { content: "How can accommodation & brain activity be measured in tandem?"; }</style>
            <h3>
              Consideration 2:
            </h3>
            <p>
              A major source of noise in the EEG signal is produced by muscles in the face and neck
            </p>
            <p class='fragment'>
              Traditionally, this has meant that EEG experiments have required participants to remain silent during recording
            </p>
            <p class='fragment'>
              Recently, work on brain-computer-interfaces (BCI) has developed tools for recovering EEG signals during complex motor tasks
            </p>
            <p class='fragment'>
              We are able to draw on this work to help minimise the noise in the EEG signal generated by speech
            </p>
          </section>

        </section>




        <!--    NEW TOP LEVEL SLIDE      -->
        <section align='left'>

          <section>
            <h2 align='center'>
              The Behavioural Experiment
              <!--           What was the methodology used? -->
            </h2>
            <aside class='notes'>

            </aside>
          </section>

          <section>
            <h3>
              Key questions
            </h3>
            <ul>
              <li>Can a standard phonetic analysis approach be used to detect accommodation across a continuous interaction?</li>
              <li>Can an HMM based analysis approach be used to detect accommodation across a continuous interaction?</li>
            </ul>
          </section>

          <section>
            <h3>
              Method
            </h3>
            <h4>Self-selection (Not reported here)</h4>
            <ul>
              <li>A self-selection protocol was designed and employed to aid in maximising accommodation</li>
              <br>
            </ul>
            <h4>Participants</h4>
            <ul>
              <li>6 female participant pairs (12 participants total)</li>
              <li>Aged 19 to 65 (mean 30.92)</li>
              <li>All born and raised in the city of Glasgow conurbation</li>
              <li>All have normal hearing and normal or corrected to normal vision</li>
            </ul>
          </section>

          <section data-state='header5'>
            <style>.header5 header:after { content: "Method"; }</style>
            <h4>Task</h4>
            <ul>
              <li>The DiapixUK task was used to elicit speech.</li>
              <li>It is a collaborative task that requires participants to work together to find a series of 12 differences between two images.</li>
            </ul>
            <img src='./resources/beach1A-comparison.svg' style='border:none; box-shadow:none'>
          </section>
          <section data-state='header5' align='center'>
            <style>.header5 header:after { content: "Method"; }</style>
            <img src='./resources/behav-layout.png' style='border:none; box-shadow:none' width=700px >
          </section>
          <section data-state='header5'>
            <style>.header5 header:after { content: "Method"; }</style>
            <h4>Transcription and Data Management</h4>
            <ul>
              <li>An orthographic transcription was conducted on the collected data, in PRAAT</li>
              <li>separate transcriptions for each member of the speaker pair</li>
              <li>LaBB-CAT was used to store the speech and transcription data, all data were force aligned</li>
            </ul>

          </section>

          <section>
            <h3>
              Phonetic Analyses
            </h3>
            <ol>
              <li>Is there a linear relationship between recent phonetic realisations of the partner and the current phonetic realisation of teh speaker?</li>
              <li class='fragment'>When the difference between partner and speaker realisations within an interaction is modelled non-linearly, is there a relationship with the presentation position?</li>
              <li class='fragment'>When the difference between partner and speaker realisations within an interaction is modelled non-linearly, is there a relationship with interaction length?</li>
            </ol>
          </section>

          <section data-state='header6'>
            <style>.header6 header:after { content: "Phonetic Analyses"; }</style>
            <h4>
              Statistical approach
            </h4>
            <p>
              Q1: Linear regression of the residuals of a linear mixed effects model of average local partner realisations against current speaker realisation
            </p>
            <p class='fragment'>
              Q2: Linear regression of the GAM predicted difference in time-normalised residuals of a linear mixed effects model of average local partner realisations against current speaker realisation for presentation position
            </p>
            <p class='fragment'>
              Q3: Linear regression of the GAM predicted difference in time-normalised residuals of a linear mixed effects model of average local partner realisations against current speaker realisation for interaction length
            </p>
          </section>

          <section data-state='header6' align='left'>
            <style>.header6 header:after { content: "Phonetic Analyses"; }</style>
            <p>
              Three acoustic-phonetic features were chosen for analysis:
            </p>
            <ul>
              <li class='fragment' data-fragment-index='1'>VOT</li>
              <li class='fragment' data-fragment-index='2'>Vowel F1 &amp; F2 values</li>
              <ul>
                <li  class='fragment' data-fragment-index='2'>STRUT</li>
                <li  class='fragment' data-fragment-index='2'>THOUGHT</li>
                <li  class='fragment' data-fragment-index='2'>TRAP</li>
              </ul>
              <li class='fragment' data-fragment-index='3'>Speech rate</li>
              <ul>
                <li  class='fragment' data-fragment-index='3'>Syllables per utterance / length of utterance</li>
              </ul>
            </ul>
          </section>

          <section data-state='header6a' align='center'>
            <style>.header6a header:after { content: "Phonetic Analyses: VOT Results"; }</style>
            <div align='left'>
              <p>
                Q1 and Q2 - No support
                <br>
                Q3:
              </p>
            </div>
            <img src='./resources/VOT-length-diff-trend.png' style='border:none; box-shadow:none' width=600px>
          </section>

          <section data-state='header6b' align='center'>
            <style>.header6b header:after { content: "Phonetic Analyses: Vowel Results"; }</style>
            <div align='left'>
              <p>
                Q1 and Q2 - No support
                <br>
                Q3:
              </p>
            </div>
            <img src='./resources/vowel-length-int.png' style='border:none; box-shadow:none' width=600px>
          </section>

          <section data-state='header6c' align='center'>
            <style>.header6c header:after { content: "Phonetic Analyses: Speech Rate Results"; }</style>
            <p align='left'>
              Q1:
            </p>
            <img src='./resources/sr-time.png' style='border:none; box-shadow:none' width=600px>
            <div align='left'>
              <p>
                Q2 and Q3 - No support
              </p>
            </div>
          </section>

          <section>
            <h3>
              What do these findings suggest?
            </h3>
            <ol>
              <li>Weak support for the detection of accommodation in a continuous interaction using acoustic-phonetic measures</li>
              <li>Some suggestion that accommodation may occur differently across different phonetic measures</li>
              <li>Context plays a role in accommodative effects</li>
            </ol>
          </section>

          <section>
            <h3>
              HMM Analyses
            </h3>
            <ul>
              <li>To assess whether the HMM based approach is able to detect adaptation patterns in the speech signal.</li>
              <li> To determine if results from the HMM based approach are compatible with the trends suggested by the phonetic analyses.</li>
            </ul>
          </section>

          <section data-state='header7'>
            <style>.header7 header:after { content: "HMM Analyses"; }</style>
            <h4>
              Basic methodological approach:
            </h4>
            <ol>
              <li>Conversion to MFCCs
                <p>Creating a holistic measure of acoustic properties</p></li>
              <li class='fragment'>Training of HMMs for each speaker
                <p>Creation of speaker recognition models</p></li>
              <li class='fragment'>Computation of likelihood ratios<br>
                <p>Accommodation detection for specific words</p></li>
              <li class='fragment'>Correlation with time<br>
                <p>Accommodation detection over time</p></li>
            </ol>
          </section>

          <section data-state='header7' align='center'>
            <style>.header7 header:after { content: "HMM Analyses"; }</style>
            <img src='./resources/detection.png' style='border:none; box-shadow:none' width=1000px>
          </section>

          <section data-state='header7'>
            <style>.header7 header:after { content: "HMM Analyses"; }</style>
            <p>
              3 types of speaker recognition models:
            </p>
            <ul>
              <li class='fragment' data-fragment-index='1'>Gaussian Mixture Model (GMM)</li>
              <ul>
                <li class='fragment' data-fragment-index='1'>General distribution of acoustic evidence in the feature space</li>
              </ul>
              <li class='fragment' data-fragment-index='2'>Left-Right Model (LR)</li>
              <ul>
                <li class='fragment' data-fragment-index='2'>Temporal patterning of observed acoustic eveidence</li>
              </ul>
              <li class='fragment' data-fragment-index='3'>Word Dependent Model (WD)</li>
              <ul>
                <li class='fragment' data-fragment-index='3'>Change in acoustic evidence over time</li>
              </ul>
            </ul>
          </section>

          <section data-state='header7'>
            <style>.header7 header:after { content: "HMM Analyses: Results"; }</style>
            <p>
              Can an HMM based approach detect adaptations in the speech signal?
            </p>
            <table>
              <tr>
                <th>Model Type</th>
                <th>No. Significant Cases</th>
                <th>p</th>
              </tr>
              <tr>
                <td style='border:none'>GMM</td>
                <td style='border:none'>57</td>
                <td style='border:none'>&lt;10<sup>-7</sup></td>
              </tr>
              <tr>
                <td style='border:none'>Left-Right</td>
                <td style='border:none'>50</td>
                <td style='border:none'>&lt;10<sup>-7</sup></td>
              </tr>
              <tr>
                <td>Word Dependent</td>
                <td>42</td>
                <td>&lt;10<sup>-7</sup></td>
              </tr>
            </table>
            <br>
            <h3 class='fragment'>
              Yes
            </h3>
          </section>

          <section data-state='header7'>
            <style>.header7 header:after { content: "HMM Analyses: Results"; }</style>
            <p>
              Do the results the results of the HMM based approach mirror those of the phonetic analyses?
            </p>
            <table>
              <tr>
                <td><img src='./resources/HMM-bar-position-beh.png'style='border:none; box-shadow:none' width=600px></td>
                <td><img src='./resources/HMM-bar-length-beh.png'style='border:none; box-shadow:none' width=600px></td>
              </tr>
            </table>
            <h3 class='fragment'>
              Yes
            </h3>
          </section>

          <section>
            <h3>
              Key findings
            </h3>
            <ul>
              <li>Detection of accommodation during short-term, continuous interactions using acoustic-phonetic measures returns only a few small effects</li>
              <li>More holistic, HMM based approaches to the detection of accommodation during short-term continuous interactions are able to classify interactions by accommodation pattern</li>
            </ul>
          </section>

        </section>




        <!--    NEW TOP LEVEL SLIDE      -->
        <section align='left'>
          <section align='center'>
            <h2>
              The Neural Experiment
              <!--         What were the results? -->
            </h2>
          </section>

          <section>
            <h3>
              Key questions
            </h3>
            <ul>
              <li>Can the findings of the HMM based approach to accommodation detection presented in the behavioural experiment be replicated?</li>
              <li class='fragment'>Is an HMM based approach able to detect shifting trends in brain activity patterns relative to an interlocutor?</li>
              <li class='fragment'>Is there a relationship between speech accommodation patterns and brain activity patterns between speakers?</li>
            </ul>
          </section>

          <section>
            <h3>
              Method
            </h3>
            <p>The same as for the behavioural experiment, except for the following two things:</p>
            <ol>
              <li>The exclusion of the self-selection protocol</li>
              <li>The application of EEG caps and collection of EEG data</li>
            </ol>
          </section>

          <section>
            <h4>
              Participants
            </h4>
            <ul>
              <li>6 female participant pairs (12 participants total)</li>
              <li>Aged 20 to 65 (mean 36.33)</li>
              <li>All born and raised in the city of Glasgow conurbation</li>
              <li>All have normal hearing and normal or corrected to normal vision</li>
            </ul>
          </section>

          <section data-state='header5' align='center'>
            <style>.header5 header:after { content: "Method"; }</style>
            <img src='./resources/neural-layout.png' style='border:none; box-shadow:none' width=1000px >
          </section>

          <section>
            <h3>
              Speech Analyses
            </h3>
          </section>

          <section data-state='SpeechAnalyses'>
            <style>.SpeechAnalyses header:after {content: 'Speech Analyses'}</style>
            <p style='font-size:30px'>
              Can the findings of the HMM based approach to accommodation detection presented in the behavioural experiment be replicated?
            </p>
            <div align='center'>
              <table>
                <tr><th style='border:none; font-size:90%'>Behavioural Exp. (speech)</th><th style='border:none; font-size:90%'>Neural Exp. (speech)</th></tr>
                <tr>
                  <td><img src='./resources/HMM-bar-length-beh.png' style='border:none; box-shadow:none' width=500px></td>
                  <td class='fragment'><img src='./resources/neural-speech-bar.png' style='border:none; box-shadow:none' width=500px></td>
                </tr>
              </table>
            </div>
            <h3 class='fragment'>
              Yes
            </h3>
          </section>

          <section>
            <h3>
              EEG Analyses
            </h3>
          </section>

          <section data-state='EEGanalyses'>
            <style>.EEGanalyses header:after {content: 'EEG Analyses'}</style>
            <h3>
              Pre-processing
            </h3>
            <ol>
              <li>Downsample to 512Hz</li>
              <li>Clean data with Artefact Subspace Reconstruction</li>
              <li>Apply PREP pipeline</li>
              <li>Reduce data contamination with ICA</li>
            </ol>
          </section>

          <section data-state='EEGanalyses'>
            <style>.EEGanalyses header:after {content: 'EEG Analyses'}</style>
            <table>
              <tr>
                <td style='border:none'><img src='./resources/EEG-noisy.png' style='border:none; box-shadow:none' width=600px></td>
              </tr>
              <tr>
                <td><img src='./resources/EEG-clean.png' style='border:none; box-shadow:none' width=600px></td>
              </tr>
            </table>
          </section>

          <section data-state='EEGanalyses'>
            <style>.EEGanalyses header:after {content: 'EEG Analyses'}</style>
            <h4>
              Basic methodological approach for EEG signal:
            </h4>
            <div style='font-size:80%'>
              <ol>
                <li>Conversion to PSD
                  <p>Creating a holistic measure of neural activity frequencies</p></li>
                <li class='fragment'>Training of HMMs for each speaker
                  <p>Creation of speaker recognition models</p></li>
                <li class='fragment'>Computation of likelihood ratios<br>
                  <p>EEG accommodation detection for specific words</p></li>
                <li class='fragment'>Correlation with time
                  <p>
                    EEG accommodation detection over time
                  </p></li>
                </div>
              </section>

            <section data-state='EEGanalyses'>
              <style>.EEGanalyses header:after {content: 'EEG Analyses'}</style>
              <p>
                The 3 types of EEG analysis:
              </p>
              <ol>
                <li class='fragment'>The EEG signal relating to when the participant is speaking</li>
                <li class='fragment'>The EEG signal relating to when the participant is not speaking</li>
                <li class='fragment'>The EEG signal across the entire interaction</li>
              </ol>
              <aside class='notes'>
                Unlike speech data, EEG data are continually produced, meaning that there is data being produced even when a participant isn't speaking.
                Because of this, we are able to look at the data in three different ways.
              </aside>
            </section>

            <section data-state='EEGanalyses1' align='center'>
              <style>.EEGanalyses1 header:after {content: 'EEG Analyses: Type 1 (Speaking)'}</style>
              <table>
                <tr>
                  <th style='border:none'>Neural Exp. (speech)</th>
                  <th style='border:none'>Neural Exp. (EEG)</th>
                </tr>
                <tr>
                  <td>
                    <img src='./resources/neural-speech-bar.png' style='border:none; box-shadow:none' width=750px>  </td>
                  <td class='fragment'>
                    <img src='./resources/EEG-bar1.png' style='border:none; box-shadow:none' width=750px>  </td>
                </tr>
              </table>

              <aside class='notes'>
                It should be noted that as with the speech data, all results presented here are not produced by chance
              </aside>
            </section>

            <section data-state='EEGanalyses2' align='center'>
              <style>.EEGanalyses2 header:after {content: 'EEG Analyses: Type 2 (Listening)'}</style>
              <img src='./resources/EEG-bar2.png' style='border:none; box-shadow:none' width=750px>
            </section>

            <section data-state='EEGanalyses3' align='center'>
              <style>.EEGanalyses3 header:after {content: 'EEG Analyses: Type 3 (All)'}</style>
              <img src='./resources/EEG-bar3.png' style='border:none; box-shadow:none' width=750px>
            </section>

            <section data-state='EEGanalyses'>
              <style>.EEGanalyses header:after {content: 'EEG Analyses'}</style>
              <ul>
                <li class='fragment'>Is an HMM based approach able to detect shifting trends in brain activity patterns relative to an interlocutor?</li>
                <p class='fragment'>
                  Maybe
                </p>
                <li class='fragment'>Is there a relationship between speech accommodation patterns and brain activity patterns between speakers?</li>
                <p class='fragment'>
                  Maybe
                </p>
              </ul>
            </section>

          </section>




          <!--    NEW TOP LEVEL SLIDE      -->
          <section align='left'>

            <section align='center'>
              <h2>
                The Conclusions
                <!--         What was the contribution to knowledge &amp; what implications atre there for the future? -->
              </h2>
            </section>

            <section>
              <h3>Behavioural</h3>
              <ul>
                <li>Accommodation occurs across a number of acoustic features.</li>
                <li class='fragment'>Considering accommodation on a continuous basis may allow for a gap to be filled.</li>
                <li class='fragment'>An HMM based approach presents a potential solution to plugging the gap between segmental and continuous measures.</li>
                <li class='fragment'>Other behavioural influences may have been overlooked in teh past due to a lack of sensitivity</li>
                <li class='fragment'>Looking at accommodation in relation to behavioural triggers may provide novel insights into accommodation</li>
              </ul>
            </section>
            <section>
              <h3>Neural</h3>
              <ul>
                <li>Further evidence for the efficacy of holistic approaches for the detection of speech accommodation is provided.</li>
                <li class='fragment'>HMM based approaches may be able to detect shifts in brain activity in relation to accommodation but improvements to the approach are needed.</li>
              </ul>
            </section>

          </section>


        </section>

      </div>
    </div>

    <script src="lib/js/head.min.js"></script>
    <script src="js/reveal.js"></script>

    <script>
      // More info https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        height:800,
        width:960,
        margin: 0.1,
        minScale: 0.2,
        maxScale:1.5,
        // Display controls in the bottom right corner
        controls: false,

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: false,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Vertical centering of slides
        center: true,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: Reveal.navigateNext,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // Hides the address bar on mobile devices
        hideAddressBar: true,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style
        transition: 'slide', // none/fade/slide/convex/concave/zoom

        // Transition speed
        transitionSpeed: 'default', // default/fast/slow

        // Transition style for full page slide backgrounds
        backgroundTransition: 'slide', // none/fade/slide/convex/concave/zoom

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Parallax background image
        parallaxBackgroundImage: '', // e.g. "'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg'"

        // Parallax background size
        parallaxBackgroundSize: '', // CSS syntax, e.g. "2100px 900px"

        // Number of pixels to move the parallax background per slide
        // - Calculated automatically unless specified
        // - Set to 0 to disable movement along an axis
        parallaxBackgroundHorizontal: null,
        parallaxBackgroundVertical: null,

        // More info https://github.com/hakimel/reveal.js#dependencies
        dependencies: [
          { src: 'lib/js/classList.js', condition: function ()
           { return !document.body.classList;}},
          { src: 'plugin/markdown/marked.js' },
          { src: 'plugin/markdown/markdown.js' },
          { src: 'plugin/notes/notes.js', async: true },
          { src: 'plugin/zoom-js/zoom.js', async: true, condition: function () { return !!document.body.classList; } },
          { src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }
        ]
      });
      Reveal.configure({ pdfMaxPagesPerSlide: 1 });
    </script>
  </body>
</html>
